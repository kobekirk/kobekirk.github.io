[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Mini Project 1: Text Analysis",
    "section": "",
    "text": "Pulp Fiction (1994) is an American crime film written and directed by renowned filmmaker Quentin Tarantino, starring John Travolta, Samuel L. Jackson, and Uma Thurman, among other notable actors. Set in Los Angeles, the movie portrays four intertwining stories of crime and violence. The film won Best Original Screenplay at the 67th Academy Awards, and received a Rotten Tomatoes score of 92%. It is important to note that Tarantino is well-known for his profound use of cuss words in his films, and specifically Pulp Fiction."
  },
  {
    "objectID": "resources.html#how-many-total-cuss-words-are-used-in-pulp-fiction",
    "href": "resources.html#how-many-total-cuss-words-are-used-in-pulp-fiction",
    "title": "Mini Project 1: Text Analysis",
    "section": "How many total cuss words are used in Pulp Fiction?",
    "text": "How many total cuss words are used in Pulp Fiction?\n\n\nCode\n# Here, I copied the code from the chunk above and added a summarize function \n# to find the total number of cuss words.\npf_words |&gt;\n  filter(is_cuss) |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(!word %in% c(\"massage\", \"hello\", \"glass\", \"massages\", \"passage\", \n                      \"associates\", \"brass\", \"embarrassed\", \"massaged\")) |&gt;\n  summarize(total_cuss_words = sum(n))\n\n\n  total_cuss_words\n1              332\n\n\nThere are 332 total cuss words used in Pulp Fiction."
  },
  {
    "objectID": "resources.html#what-is-the-proportion-of-cuss-words-to-normal-words-in-pulp-fiction",
    "href": "resources.html#what-is-the-proportion-of-cuss-words-to-normal-words-in-pulp-fiction",
    "title": "Mini Project 1: Text Analysis",
    "section": "What is the proportion of cuss words to normal words in Pulp Fiction?",
    "text": "What is the proportion of cuss words to normal words in Pulp Fiction?\n\n\nCode\n# Here I defined the non-cuss words that were appearing in cuss_words as \n# \"not_cuss.\" Then I created a new tibble, pf_summary, which is a new summary \n# of total words in the movie, total cuss words in the movie, and finally, the\n# proportion of cuss words to total words.\nnot_cuss &lt;- c(\"massage\", \"hello\", \"glass\", \"massages\", \"passage\", \"associates\",\n              \"brass\", \"embarrassed\", \"massaged\")\n\npf_summary &lt;- pf_words |&gt;\n  summarize(\n    total_words = n(),\n    total_cuss_words = sum(is_cuss & !word %in% not_cuss),\n    prop_cuss = total_cuss_words / total_words\n  )\n\npf_summary\n\n\n  total_words total_cuss_words  prop_cuss\n1       14470              332 0.02294402\n\n\nApproximately 2.3% of ALL of the words spoken in Pulp Fiction are cuss words. This equates to about 1 in every 43 words being a cuss word."
  },
  {
    "objectID": "resources.html#what-character-in-pulp-fiction-says-the-most-cuss-words-what-character-has-the-highest-proportion-of-cuss-words-in-their-dialogue",
    "href": "resources.html#what-character-in-pulp-fiction-says-the-most-cuss-words-what-character-has-the-highest-proportion-of-cuss-words-in-their-dialogue",
    "title": "Mini Project 1: Text Analysis",
    "section": "What character in Pulp Fiction says the most cuss words? What character has the highest proportion of cuss words in their dialogue?",
    "text": "What character in Pulp Fiction says the most cuss words? What character has the highest proportion of cuss words in their dialogue?\n\n\nCode\n# Here I am creating a new tibble, character_words. This shows each character's \n# total words, cuss words, and proportion of cuss words. I also filtered out \n# characters that don't have at least 100 words of dialogue.\nnot_cuss &lt;- c(\"massage\", \"hello\", \"glass\", \"massages\", \"passage\", \"associates\",\n              \"brass\", \"embarrassed\", \"massaged\")\n\ncharacter_words &lt;- pf_words |&gt;\n  group_by(character) |&gt;\n  summarize(\n    total_words = n(),\n    cuss_words = sum(is_cuss & !word %in% not_cuss),\n    prop_cuss = cuss_words / total_words\n  ) |&gt;\n  filter(total_words &gt; 100) |&gt;\n  arrange(desc(prop_cuss))\n\ncharacter_words\n\n\n# A tibble: 15 × 4\n   character   total_words cuss_words prop_cuss\n   &lt;chr&gt;             &lt;int&gt;      &lt;int&gt;     &lt;dbl&gt;\n 1 Marsellus           465         27   0.0581 \n 2 Lance               696         31   0.0445 \n 3 Jules              3251        131   0.0403 \n 4 Jody                213          7   0.0329 \n 5 Jimmie              398         13   0.0327 \n 6 Honey Bunny         268          8   0.0299 \n 7 Vincent            2596         57   0.0220 \n 8 Pumpkin             883         19   0.0215 \n 9 Maynard             157          2   0.0127 \n10 Butch              1259         12   0.00953\n11 Capt. Koons         538          5   0.00929\n12 The Wolf           1120          9   0.00804\n13 Fabienne            706          3   0.00425\n14 Mia                1017          4   0.00393\n15 Esmarelda           155          0   0      \n\n\nJules says the most cuss words of any character, using 131 cuss words throughout the movie. However, Marsellus uses the highest proportion of cuss words in the movie, with 5.8% of his total dialogue consisting of cuss words, which equates to approximately 1 of every 17 words Marsellus says being a cuss word.\nHere is a graph that portrays the characters and their corresponding proportion of cuss words.\n\n\nCode\n# Here I used geom_col to plot characters and their proportion of cuss words,\n# filling the bars in blue and labeling the axes and title.\nggplot(character_words, aes(x = reorder(character, prop_cuss), y = prop_cuss)) +\n  geom_col(fill = \"blue\") +\n  coord_flip() +\n  labs(\n    title = \"Proportion of Cuss Words by Characters in Pulp Fiction\",\n    x = \"Character\",\n    y = \"Proportion of Cuss Words\"\n  ) +\n  scale_y_continuous(labels = scales::percent_format())\n\n\n\n\n\n\n\n\n\nHere is a graph that portrays the characters and their corresponding total count of cuss words.\n\n\nCode\n# Here I used geom_col to plot characters and their total number of cuss words,\n# filling the bars in blue and labeling the axes and title.\nggplot(character_words, aes(x = reorder(character, cuss_words), y = cuss_words)) +\n  geom_col(fill = \"blue\") +\n  coord_flip() +\n  labs(\n    title = \"Total Cuss Words by Characters in Pulp Fiction\",\n    x = \"Character\",\n    y = \"Count of Cuss Words\"\n  )"
  },
  {
    "objectID": "resources.html#is-the-most-common-word-in-pulp-fiction-besides-stop-words-a-cuss-word-how-many-cuss-words-are-in-the-top-10-words-in-pulp-fiction-besides-stop-words",
    "href": "resources.html#is-the-most-common-word-in-pulp-fiction-besides-stop-words-a-cuss-word-how-many-cuss-words-are-in-the-top-10-words-in-pulp-fiction-besides-stop-words",
    "title": "Mini Project 1: Text Analysis",
    "section": "Is the most common word in Pulp Fiction, besides stop words, a cuss word? How many cuss words are in the top 10 words in Pulp Fiction, besides stop words?",
    "text": "Is the most common word in Pulp Fiction, besides stop words, a cuss word? How many cuss words are in the top 10 words in Pulp Fiction, besides stop words?\n\n\nCode\n# In this code, I anti-join the stop words with pf_words. Then I count the \n# words, filter out NA as a word, and graph the top 20 most common words using\n# geom_col in a similar style as before.\npf_words |&gt;\n  anti_join(smart_stopwords) |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(word != \"NA\") |&gt;\n  slice_max(n, n = 20) |&gt;\n  ggplot(aes(fct_reorder(word, n), n)) +\n  geom_col(fill = \"blue\") +\n  coord_flip() +\n    labs(\n    title = \"Most Common Words in Pulp Fiction\",\n    subtitle = \"(excluding stop words)\",\n    x = \"Words\",\n    y = \"Number of Times Spoken\"\n  )\n\n\n\n\n\n\n\n\n\nYes, the most common word, outside of stop words, is a cuss word. In fact, 4 of the 10 most common words in the movie are cuss words!\n\n\nCode\n# Here I create a new tibble, words_by_character, grouping characters with the\n# words they said, and how many times they said that word.\nwords_by_character &lt;- pf_words |&gt;\n  group_by(character, word) |&gt;\n  summarize(n = n(), .groups = \"drop\")"
  },
  {
    "objectID": "resources.html#what-are-each-characters-most-common-words-excluding-stop-words-do-any-characters-have-a-cuss-word-as-their-most-common-word",
    "href": "resources.html#what-are-each-characters-most-common-words-excluding-stop-words-do-any-characters-have-a-cuss-word-as-their-most-common-word",
    "title": "Mini Project 1: Text Analysis",
    "section": "What are each character’s most common words, excluding stop words? Do any characters have a cuss word as their most common word?",
    "text": "What are each character’s most common words, excluding stop words? Do any characters have a cuss word as their most common word?\nJules, played by Samuel L. Jackson, said “shit” 33 times during the film, making that his most frequently used word. His partner in crime, Vincent, also most frequently used a specific cuss word. In fact, 4 characters in the top 10 of most repeated words used a specific cuss word most frequently!"
  },
  {
    "objectID": "resources.html#what-are-the-most-common-words-used-in-pulp-fiction-excluding-stop-words-and-cuss-words",
    "href": "resources.html#what-are-the-most-common-words-used-in-pulp-fiction-excluding-stop-words-and-cuss-words",
    "title": "Mini Project 1: Text Analysis",
    "section": "What are the most common words used in Pulp Fiction, excluding stop words AND cuss words?",
    "text": "What are the most common words used in Pulp Fiction, excluding stop words AND cuss words?\n\n\nCode\n# First, I made a new tibble excluding stop words and cuss words, but including\n# not_cuss from earlier. Then I made a wordcloud with the most frequent \n# non-cuss words in the movie.\nall_but_cuss &lt;- pf_words |&gt;\n  anti_join(smart_stopwords) |&gt;\n  filter(!is_cuss, !word %in% not_cuss) |&gt;\n  count(word, sort = TRUE)\n\nwordcloud(\n  words = all_but_cuss$word,\n  freq = all_but_cuss$n,\n  max.words = 50,\n  random.order = FALSE,\n  colors = brewer.pal(6, \"Dark2\")\n)\n\n\n\n\n\n\n\n\n\nAs you can see in the wordcloud above, “gonna” is the most common non-cuss word. Some other common words are “man”, “good”, and “Marsellus”. While I wanted to create a wholesome picture for the audience by excluding cuss words, it’s still true that this wordcloud contains words like “dead”, “fight”, and “gun”. Oh well.\nGoing into this project, I was well aware of the high amount of cuss words used in Pulp Fiction. What I didn’t know was that 2.3% of all words in the entire movie were cuss words. I also didn’t know that Marsellus had almost 6% of his entire dialogue being cuss words, or that Jules used over twice as many cuss words as the next highest character. Those are just a few of the conclusions I was able to draw through my analysis of the Pulp Fiction script."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kobe Kirk",
    "section": "",
    "text": "Hi everyone, I’m Kobe. I am a senior Quantitative Economics major at St. Olaf College, with concentrations in both Statistics and Data Science and Management Studies. I’m passionate about data analysis and drawing conclusions from data. I play basketball at St. Olaf, but I love all sports, and outside of my studies and sports I enjoy fishing and golfing."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Kobe Kirk",
    "section": "Education",
    "text": "Education\n\nBA in Quantitative Economics, St. Olaf College\nConcentrations: Statistics & Data Science; Management Studies\nExpected graduation May 2026"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mini Project 3: Maps",
    "section": "",
    "text": "Code\nlibrary(rvest)\nlibrary(sf)\nlibrary(polite)\nlibrary(viridis)\nlibrary(leaflet)\nlibrary(htmltools)\nlibrary(glue)\nlibrary(tidyverse)\nlibrary(maps)\nlibrary(mdsr)\nlibrary(readr)\n\n\n\n\nCode\n# Loads the raw NFHS high school sports dataset from a CSV file into R\nnfhs_data &lt;- read.csv(\"/Users/kobekirk/GitHub/kobekirk.github.io/2024 High School Sports Data.csv\", header = TRUE)\n\n\n\n\nCode\n# Removes states not needed for mapping, converts state names to lowercase, and removes commas from the numbers in the data\nnfhs_data_clean &lt;- nfhs_data |&gt;\n  filter(!State %in% c(\"Alaska\", \"Hawaii\", \"Dist. of Columbia\")) |&gt;\n  mutate(State = str_to_lower(State),\n         across(-State, parse_number))\n\n\n\n\nCode\n# Loads built-in polygon coordinates for US states and draws a basic outline map for reference\nus_states &lt;- map_data(\"state\")\nhead(us_states)\n\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nCode\nus_states |&gt;\n  ggplot(data = us_states, mapping = aes(x = long, y = lat,\n                          group = group)) + \n  geom_polygon(fill = \"white\", color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Cleans remaining inconsistent state names, then checks which states do not successfully match between the NFHS dataset and the base map\nnfhs_data_clean &lt;- nfhs_data_clean |&gt;\n  mutate(State = str_replace(State, \" state\", \"\"))\n\nnfhs_data_clean |&gt;\n  anti_join(us_states, by = c(\"State\" = \"region\"))\n\n\n [1] State                   Baseball.Players        Basketball.Players     \n [4] Cross.Country.Players   Football.Players        Golf.Players           \n [7] Hockey.Players          Soccer.Players          Tennis.Players         \n[10] Track.and.Field.Players Wrestling.Players      \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nCode\nus_states |&gt;\n  anti_join(nfhs_data_clean, by = c(\"region\" = \"State\")) %&gt;%\n  count(region)\n\n\n                region  n\n1 district of columbia 10\n\n\n\n\nCode\n# Joins NFHS data with polygon map data and produces a static choropleth map showing the number of basketball players in each state\nlibrary(viridis) # for color schemes\nnfhs_data_clean |&gt;\n  mutate(\n    State = str_to_lower(State),              \n  ) |&gt;\n  right_join(us_states, by = c(\"State\" = \"region\")) |&gt;\n  ggplot(aes(long, lat, group = group)) +\n  geom_polygon(aes(fill = Basketball.Players), color = \"black\") +\n  coord_map() +\n  theme_void() +\n  scale_fill_viridis(option = \"plasma\") +\n  labs(fill = \"Number of Players\",\n       title = \"High School Basketball Players per State\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Get info to draw US states for geom_polygon (connect the lat-long points)\nstates_polygon &lt;- as_tibble(map_data(\"state\")) |&gt;\n  select(region, group, order, lat, long)\n\n# See what the state (region) levels look like in states_polygon\nunique(states_polygon$region)\n\n\n [1] \"alabama\"              \"arizona\"              \"arkansas\"            \n [4] \"california\"           \"colorado\"             \"connecticut\"         \n [7] \"delaware\"             \"district of columbia\" \"florida\"             \n[10] \"georgia\"              \"idaho\"                \"illinois\"            \n[13] \"indiana\"              \"iowa\"                 \"kansas\"              \n[16] \"kentucky\"             \"louisiana\"            \"maine\"               \n[19] \"maryland\"             \"massachusetts\"        \"michigan\"            \n[22] \"minnesota\"            \"mississippi\"          \"missouri\"            \n[25] \"montana\"              \"nebraska\"             \"nevada\"              \n[28] \"new hampshire\"        \"new jersey\"           \"new mexico\"          \n[31] \"new york\"             \"north carolina\"       \"north dakota\"        \n[34] \"ohio\"                 \"oklahoma\"             \"oregon\"              \n[37] \"pennsylvania\"         \"rhode island\"         \"south carolina\"      \n[40] \"south dakota\"         \"tennessee\"            \"texas\"               \n[43] \"utah\"                 \"vermont\"              \"virginia\"            \n[46] \"washington\"           \"west virginia\"        \"wisconsin\"           \n[49] \"wyoming\"             \n\n\nCode\n# Get info to draw US states for geom_sf and leaflet (simple features\n#   object with multipolygon geometry column)\nstates_sf &lt;- \n  read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\") |&gt;\n  select(name, geometry)\n\n# See what the state (name) levels look like in states_sf\nunique(states_sf$name)\n\n\n [1] \"Alabama\"              \"Alaska\"               \"Arizona\"             \n [4] \"Arkansas\"             \"California\"           \"Colorado\"            \n [7] \"Connecticut\"          \"Delaware\"             \"District of Columbia\"\n[10] \"Florida\"              \"Georgia\"              \"Hawaii\"              \n[13] \"Idaho\"                \"Illinois\"             \"Indiana\"             \n[16] \"Iowa\"                 \"Kansas\"               \"Kentucky\"            \n[19] \"Louisiana\"            \"Maine\"                \"Maryland\"            \n[22] \"Massachusetts\"        \"Michigan\"             \"Minnesota\"           \n[25] \"Mississippi\"          \"Missouri\"             \"Montana\"             \n[28] \"Nebraska\"             \"Nevada\"               \"New Hampshire\"       \n[31] \"New Jersey\"           \"New Mexico\"           \"New York\"            \n[34] \"North Carolina\"       \"North Dakota\"         \"Ohio\"                \n[37] \"Oklahoma\"             \"Oregon\"               \"Pennsylvania\"        \n[40] \"Rhode Island\"         \"South Carolina\"       \"South Dakota\"        \n[43] \"Tennessee\"            \"Texas\"                \"Utah\"                \n[46] \"Vermont\"              \"Virginia\"             \"Washington\"          \n[49] \"West Virginia\"        \"Wisconsin\"            \"Wyoming\"             \n[52] \"Puerto Rico\"         \n\n\nCode\n# See what the state (state_name) levels look like in nfhs_data_clean\nunique(nfhs_data_clean$State)   \n\n\n [1] \"alabama\"        \"arizona\"        \"arkansas\"       \"california\"    \n [5] \"colorado\"       \"connecticut\"    \"delaware\"       \"florida\"       \n [9] \"georgia\"        \"idaho\"          \"illinois\"       \"indiana\"       \n[13] \"iowa\"           \"kansas\"         \"kentucky\"       \"louisiana\"     \n[17] \"maine\"          \"maryland\"       \"massachusetts\"  \"michigan\"      \n[21] \"minnesota\"      \"mississippi\"    \"missouri\"       \"montana\"       \n[25] \"nebraska\"       \"nevada\"         \"new hampshire\"  \"new jersey\"    \n[29] \"new mexico\"     \"new york\"       \"north carolina\" \"north dakota\"  \n[33] \"ohio\"           \"oklahoma\"       \"oregon\"         \"pennsylvania\"  \n[37] \"rhode island\"   \"south carolina\" \"south dakota\"   \"tennessee\"     \n[41] \"texas\"          \"utah\"           \"vermont\"        \"virginia\"      \n[45] \"washington\"     \"west virginia\"  \"wisconsin\"      \"wyoming\"       \n\n\nCode\n# all lower case plus some extraneous rows\n\n# Make sure all keys have the same format before joining: all lower case\nstates_sf &lt;- states_sf |&gt;\n  mutate(name = str_to_lower(name))\n\n\n\n\nCode\n# Now we can merge data sets together for the static and the interactive plots\n\n# Merge with states_polygon (static)\nnfhs_polygon &lt;- states_polygon |&gt;\n  left_join(nfhs_data_clean, by = c(\"region\" = \"State\"))\nnfhs_polygon\n\n\n# A tibble: 15,537 × 15\n   region  group order   lat  long Baseball.Players Basketball.Players\n   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;              &lt;dbl&gt;\n 1 alabama     1     1  30.4 -87.5            16284              19459\n 2 alabama     1     2  30.4 -87.5            16284              19459\n 3 alabama     1     3  30.4 -87.5            16284              19459\n 4 alabama     1     4  30.3 -87.5            16284              19459\n 5 alabama     1     5  30.3 -87.6            16284              19459\n 6 alabama     1     6  30.3 -87.6            16284              19459\n 7 alabama     1     7  30.3 -87.6            16284              19459\n 8 alabama     1     8  30.3 -87.6            16284              19459\n 9 alabama     1     9  30.3 -87.7            16284              19459\n10 alabama     1    10  30.3 -87.8            16284              19459\n# ℹ 15,527 more rows\n# ℹ 8 more variables: Cross.Country.Players &lt;dbl&gt;, Football.Players &lt;dbl&gt;,\n#   Golf.Players &lt;dbl&gt;, Hockey.Players &lt;dbl&gt;, Soccer.Players &lt;dbl&gt;,\n#   Tennis.Players &lt;dbl&gt;, Track.and.Field.Players &lt;dbl&gt;,\n#   Wrestling.Players &lt;dbl&gt;\n\n\nCode\n# Looks like merge worked for 48 contiguous states plus DC\nnfhs_polygon |&gt;\n  group_by(region) |&gt;\n  summarise(mean = mean(Basketball.Players)) |&gt;\n  print(n = Inf)\n\n\n# A tibble: 49 × 2\n   region                mean\n   &lt;chr&gt;                &lt;dbl&gt;\n 1 alabama              19459\n 2 arizona               8943\n 3 arkansas              6364\n 4 california           46402\n 5 colorado              9710\n 6 connecticut           5273\n 7 delaware              1549\n 8 district of columbia    NA\n 9 florida              21030\n10 georgia              11752\n11 idaho                 3902\n12 illinois             20723\n13 indiana              10310\n14 iowa                 10238\n15 kansas                8247\n16 kentucky              6709\n17 louisiana             7961\n18 maine                 3502\n19 maryland              5377\n20 massachusetts        12698\n21 michigan             20536\n22 minnesota            14181\n23 mississippi          11010\n24 missouri             13117\n25 montana               3410\n26 nebraska              6502\n27 nevada                3228\n28 new hampshire         2472\n29 new jersey           14379\n30 new mexico            4062\n31 new york             20430\n32 north carolina       11491\n33 north dakota          2937\n34 ohio                 20672\n35 oklahoma              9581\n36 oregon                7530\n37 pennsylvania         21690\n38 rhode island          2235\n39 south carolina        6679\n40 south dakota          3418\n41 tennessee             8275\n42 texas                62977\n43 utah                  4094\n44 vermont                697\n45 virginia              9312\n46 washington           11550\n47 west virginia         2660\n48 wisconsin            15016\n49 wyoming               1753\n\n\nCode\n# Remove DC since such an outlier\nnfhs_polygon &lt;- nfhs_polygon |&gt;\n  filter(region != \"district of columbia\")\n\n\n# Merge with states_sf (static or interactive)\nnfhs_sf &lt;- states_sf |&gt;\n  left_join(nfhs_data_clean, by = c(\"name\" = \"State\")) |&gt;\n  filter(!(name %in% c(\"alaska\", \"hawaii\", \"district of columbia\", \"puerto rico\")))\n\n# Looks like merge worked for 48 contiguous states\nclass(nfhs_sf)\n\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nCode\nprint(nfhs_sf, n = Inf)\n\n\nSimple feature collection with 48 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7066 ymin: 25.12078 xmax: -66.9796 ymax: 49.38362\nGeodetic CRS:  WGS 84\n# A tibble: 48 × 12\n   name                             geometry Baseball.Players Basketball.Players\n * &lt;chr&gt;                  &lt;MULTIPOLYGON [°]&gt;            &lt;dbl&gt;              &lt;dbl&gt;\n 1 alabama        (((-87.3593 35.00118, -85…            16284              19459\n 2 arizona        (((-109.0425 37.00026, -1…             8074               8943\n 3 arkansas       (((-94.47384 36.50186, -9…             6126               6364\n 4 california     (((-123.2333 42.00619, -1…            42972              46402\n 5 colorado       (((-107.9197 41.00391, -1…             7884               9710\n 6 connecticut    (((-73.05353 42.03905, -7…             4459               5273\n 7 delaware       (((-75.41409 39.80446, -7…             1348               1549\n 8 florida        (((-85.49714 30.99754, -8…            18230              21030\n 9 georgia        (((-83.10919 35.00118, -8…            12098              11752\n10 idaho          (((-116.0475 49.00024, -1…             2649               3902\n11 illinois       (((-90.63998 42.51006, -8…            19322              20723\n12 indiana        (((-85.99006 41.75972, -8…            10256              10310\n13 iowa           (((-91.36842 43.50139, -9…             9945              10238\n14 kansas         (((-101.906 40.00163, -95…             6441               8247\n15 kentucky       (((-83.90335 38.76931, -8…             7315               6709\n16 louisiana      (((-93.60849 33.01853, -9…             8811               7961\n17 maine          (((-70.70392 43.05776, -7…             2899               3502\n18 maryland       (((-75.99465 37.95325, -7…             5141               5377\n19 massachusetts  (((-70.91752 42.88797, -7…            10939              12698\n20 michigan       (((-83.45424 41.73234, -8…            16044              20536\n21 minnesota      (((-92.0147 46.7054, -92.…            12390              14181\n22 mississippi    (((-88.47111 34.9957, -88…             7290              11010\n23 missouri       (((-91.83396 40.60957, -9…            12711              13117\n24 montana        (((-104.0475 49.00024, -1…              851               3410\n25 nebraska       (((-103.3246 43.00299, -1…             3036               6502\n26 nevada         (((-117.0279 42.00071, -1…             2446               3228\n27 new hampshire  (((-71.08183 45.3033, -71…             2173               2472\n28 new jersey     (((-74.23655 41.14083, -7…            13321              14379\n29 new mexico     (((-107.4213 37.00026, -1…             3306               4062\n30 new york       (((-73.34381 45.01303, -7…            16358              20430\n31 north carolina (((-80.97866 36.56211, -8…            10385              11491\n32 north dakota   (((-97.22874 49.00024, -9…             1838               2937\n33 ohio           (((-80.5186 41.9788, -80.…            21733              20672\n34 oklahoma       (((-100.0877 37.00026, -9…             9155               9581\n35 oregon         (((-123.2113 46.17414, -1…             5654               7530\n36 pennsylvania   (((-79.76278 42.25265, -7…            20672              21690\n37 rhode island   (((-71.19684 41.67757, -7…             1583               2235\n38 south carolina (((-82.76414 35.0669, -82…             7029               6679\n39 south dakota   (((-104.0475 45.94411, -9…                0               3418\n40 tennessee      (((-88.05487 36.49638, -8…             8889               8275\n41 texas          (((-101.8129 36.50186, -1…            53923              62977\n42 utah           (((-112.1644 41.99523, -1…             4064               4094\n43 vermont        (((-71.50355 45.01303, -7…              597                697\n44 virginia       (((-75.39766 38.0135, -75…             8816               9312\n45 washington     (((-117.0334 49.00024, -1…             9593              11550\n46 west virginia  (((-80.5186 40.63695, -80…             2661               2660\n47 wisconsin      (((-90.41543 46.56848, -9…            12077              15016\n48 wyoming        (((-109.0808 45.00207, -1…                0               1753\n# ℹ 8 more variables: Cross.Country.Players &lt;dbl&gt;, Football.Players &lt;dbl&gt;,\n#   Golf.Players &lt;dbl&gt;, Hockey.Players &lt;dbl&gt;, Soccer.Players &lt;dbl&gt;,\n#   Tennis.Players &lt;dbl&gt;, Track.and.Field.Players &lt;dbl&gt;,\n#   Wrestling.Players &lt;dbl&gt;\n\n\n\n\nCode\n# Create our own category bins for number of players\n#   and assign the yellow-orange-red color palette\nbins &lt;- c(0, 1000, 2000, 5000, 10000, 20000, 40000, 60000, Inf)\npal &lt;- colorBin(\"YlOrRd\", domain = nfhs_sf$Basketball.Players, bins = bins)\n\n# Create labels that pop up when we hover over a state.  The labels must\n#   be part of a list where each entry is tagged as HTML code.\nnfhs_sf &lt;- nfhs_sf |&gt;\n  mutate(labels = str_c(name, \": \", Basketball.Players, \" basketball players\"))\nlabels &lt;- lapply(nfhs_sf$labels, HTML)\n\n# If want more HTML formatting, use these lines instead of those above:\n# states &lt;- states |&gt;\n#   mutate(labels = glue(\"&lt;strong&gt;{name}&lt;/strong&gt;&lt;br/&gt;{Basketball.Players} people / \n#   mi&lt;sup&gt;2&lt;/sup&gt;\"))\n# labels &lt;- lapply(states$labels, HTML)\n\nleaflet(nfhs_sf) |&gt;\n  setView(-96, 37.8, 4) |&gt;\n  addTiles() |&gt;\n  addControl(\n  html = \"&lt;div style='width:100%; text-align:center;'&gt;\n            &lt;h3&gt;High School Basketball Players by State&lt;/h3&gt;\n          &lt;/div&gt;\",\n  position = \"topright\"\n) |&gt;\n  addPolygons(\n    fillColor = ~pal(Basketball.Players),\n    weight = 2,\n    opacity = 1,\n    color = \"white\",\n    dashArray = \"3\",\n    fillOpacity = 0.7,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"#666\",\n      dashArray = \"\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE),\n    label = labels,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\")) |&gt;\n  addLegend(pal = pal, values = ~Basketball.Players, opacity = 0.7, title = \"Number of Players\",\n    position = \"bottomright\")\n\n\n\n\n\n\n\n\nCode\n# For each state, finds the sport with the highest number of participants and stores it in a new column called Most.Popular.Sport\nnfhs_data_clean &lt;- nfhs_data_clean |&gt;\n  rowwise() |&gt;\n  mutate(\n    Most.Popular.Sport = cur_data() |&gt; \n      select(ends_with(\"Players\")) |&gt; \n      {\\(.) names(.)[which.max(unlist(.))] }(),\n    Most.Popular.Sport = str_remove(Most.Popular.Sport, \"\\\\.Players$\")\n  ) |&gt;\n  ungroup()\n\n\n\n\nCode\n# Creates a categorical static map, where each state is colored by its most popular sport\nlibrary(viridis) # for color schemes\nnfhs_data_clean |&gt;\n  right_join(us_states, by = c(\"State\" = \"region\")) |&gt;\n  ggplot(aes(long, lat, group = group)) +\n  geom_polygon(aes(fill = Most.Popular.Sport), color = \"black\") +\n  coord_map() +\n  theme_void() +\n  scale_fill_viridis_d(option = \"plasma\") +\n  labs(fill = \"Sport\",\n       title = \"Most Popular Boys High School Sport in Each State\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nnfhs_sf &lt;- states_sf |&gt;\n  left_join(nfhs_data_clean, by = c(\"name\" = \"State\")) |&gt;\n  filter(!(name %in% c(\"alaska\", \"hawaii\", \"district of columbia\", \"puerto rico\")))\n\nsports &lt;- na.omit(unique(nfhs_sf$Most.Popular.Sport))\n\npal &lt;- colorFactor(\n  palette = \"Set3\",   # You can choose another palette if you prefer\n  domain = sports\n)\n\n# Create hover labels\nnfhs_sf &lt;- nfhs_sf |&gt;\n  mutate(\n    labels = str_c(\n      \"&lt;strong&gt;\", name, \"&lt;/strong&gt;&lt;br/&gt;\",\n      \"Most Popular Sport: &lt;strong&gt;\", Most.Popular.Sport, \"&lt;/strong&gt;\"\n    )\n  )\n\nlabels &lt;- lapply(nfhs_sf$labels, HTML)\n\n# Make the interactive Leaflet map\nleaflet(nfhs_sf) |&gt;\n  setView(-96, 37.8, 4) |&gt;\n  addTiles() |&gt;\n  addControl(\n    html = \"&lt;h3 style='text-align:center;'&gt;Most Popular Sport by State&lt;/h3&gt;\",\n    position = \"topright\"\n  ) |&gt;\n  addPolygons(\n    fillColor = ~pal(Most.Popular.Sport),\n    weight = 2,\n    opacity = 1,\n    color = \"white\",\n    dashArray = \"3\",\n    fillOpacity = 0.7,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"#666\",\n      dashArray = \"\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE\n    ),\n    label = labels,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\"\n    )\n  ) |&gt;\n  addLegend(\n    pal = pal,\n    values = ~Most.Popular.Sport,\n    opacity = 0.7,\n    title = \"Most Popular Sport\",\n    position = \"bottomright\"\n  )\n\n\n\n\n\n\n\n\nCode\nlibrary(sf)\nstates &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\")\nclass(states)\nstates\n\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\nSimple feature collection with 52 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -188.9049 ymin: 17.92956 xmax: -65.6268 ymax: 71.35163\nGeodetic CRS:  WGS 84\n# A tibble: 52 × 4\n   id    name                  density                                  geometry\n   &lt;chr&gt; &lt;chr&gt;                   &lt;dbl&gt;                        &lt;MULTIPOLYGON [°]&gt;\n 1 01    Alabama                 94.6  (((-87.3593 35.00118, -85.60667 34.98475…\n 2 02    Alaska                   1.26 (((-131.602 55.11798, -131.5692 55.28229…\n 3 04    Arizona                 57.0  (((-109.0425 37.00026, -109.048 31.33163…\n 4 05    Arkansas                56.4  (((-94.47384 36.50186, -90.15254 36.4963…\n 5 06    California             242.   (((-123.2333 42.00619, -122.3789 42.0116…\n 6 08    Colorado                49.3  (((-107.9197 41.00391, -105.729 40.99843…\n 7 09    Connecticut            739.   (((-73.05353 42.03905, -71.79931 42.0226…\n 8 10    Delaware               464.   (((-75.41409 39.80446, -75.5072 39.68396…\n 9 11    District of Columbia 10065    (((-77.03526 38.99387, -76.90929 38.8952…\n10 12    Florida                353.   (((-85.49714 30.99754, -85.00421 31.0030…\n# ℹ 42 more rows"
  }
]